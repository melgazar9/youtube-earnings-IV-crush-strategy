{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43fdf648-a094-48d6-b12b-b4d7e63e7c9e",
   "metadata": {},
   "source": [
    "### Disclaimer\n",
    "\n",
    "This software is provided solely for educational and research purposes. \n",
    "It is not intended to provide investment advice, and no investment recommendations are made herein. \n",
    "The developers are not financial advisors and accept no responsibility for any financial decisions or losses resulting from the use of this software. \n",
    "Always consult a professional financial advisor before making any investment decisions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ec895f-8619-4f60-b557-038dc8307894",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31408327-88f1-4fe1-9b15-87a2e3918e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import argparse\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import plotly.express as px\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\"\n",
    "\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "pd.options.display.max_columns = 30\n",
    "warnings.filterwarnings(\"ignore\", message=\"Not enough unique days to interpolate for ticker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec6d53-99a5-4710-b517-e1abfd30760c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ticker = \"META\"\n",
    "ticker_obj = yf.Ticker(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f212cf-54c4-47ed-ab3e-3129f570c199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "from datetime import datetime, timedelta\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import argparse\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "import plotly.express as px\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pytz\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Not enough unique days to interpolate for ticker\")\n",
    "\n",
    "### ------ Globals ------ ###\n",
    "\n",
    "MIN_AVG_30D_DOLLAR_VOLUME = 10_000_000\n",
    "MIN_AVG_30D_SHARE_VOLUME = 1_500_500\n",
    "MIN_IV30_RV30 = 1.35\n",
    "MAX_TS_SLOPE_0_45 = -0.0050\n",
    "MIN_SHARE_PRICE = 15\n",
    "EARNINGS_LOOKBACK_DAYS_FOR_AGG = 365 * 3\n",
    "PLOT_LOC = \"/Users/melgazar9/tmp_plots/\"\n",
    "\n",
    "\n",
    "def filter_dates(dates):\n",
    "    today = datetime.today().date()\n",
    "    cutoff_date = today + timedelta(days=45)\n",
    "\n",
    "    sorted_dates = sorted(datetime.strptime(date, \"%Y-%m-%d\").date() for date in dates)\n",
    "\n",
    "    arr = []\n",
    "    for i, date in enumerate(sorted_dates):\n",
    "        if date >= cutoff_date:\n",
    "            arr = [d.strftime(\"%Y-%m-%d\") for d in sorted_dates[: i + 1]]\n",
    "            break\n",
    "\n",
    "    if len(arr) > 0:\n",
    "        if arr[0] == today.strftime(\"%Y-%m-%d\"):\n",
    "            return arr[1:]\n",
    "        return arr\n",
    "\n",
    "    raise ValueError(\"No date 45 days or more in the future found.\")\n",
    "\n",
    "\n",
    "def yang_zhang(price_data, window=30, trading_periods=252, return_last_only=True):\n",
    "    log_ho = (price_data[\"High\"] / price_data[\"Open\"]).apply(np.log)\n",
    "    log_lo = (price_data[\"Low\"] / price_data[\"Open\"]).apply(np.log)\n",
    "    log_co = (price_data[\"Close\"] / price_data[\"Open\"]).apply(np.log)\n",
    "\n",
    "    log_oc = (price_data[\"Open\"] / price_data[\"Close\"].shift(1)).apply(np.log)\n",
    "    log_oc_sq = log_oc ** 2\n",
    "\n",
    "    log_cc = (price_data[\"Close\"] / price_data[\"Close\"].shift(1)).apply(np.log)\n",
    "    log_cc_sq = log_cc ** 2\n",
    "\n",
    "    rs = log_ho * (log_ho - log_co) + log_lo * (log_lo - log_co)\n",
    "\n",
    "    close_vol = log_cc_sq.rolling(window=window, center=False).sum() * (1.0 / (window - 1.0))\n",
    "\n",
    "    open_vol = log_oc_sq.rolling(window=window, center=False).sum() * (1.0 / (window - 1.0))\n",
    "\n",
    "    window_rs = rs.rolling(window=window, center=False).sum() * (1.0 / (window - 1.0))\n",
    "\n",
    "    k = 0.3333 / (1.3333 + ((window + 1) / (window - 1)))\n",
    "    result = (open_vol + k * close_vol + (1 - k) * window_rs).apply(np.sqrt) * np.sqrt(trading_periods)\n",
    "\n",
    "    if return_last_only:\n",
    "        return result.iloc[-1]\n",
    "    else:\n",
    "        return result.dropna()\n",
    "\n",
    "\n",
    "def build_term_structure(days, ivs):\n",
    "    days = np.array(days)\n",
    "    ivs = np.array(ivs)\n",
    "\n",
    "    # Sort by days\n",
    "    sort_idx = days.argsort()\n",
    "    days = days[sort_idx]\n",
    "    ivs = ivs[sort_idx]\n",
    "\n",
    "    _, unique_idx = np.unique(days, return_index=True)\n",
    "    days = days[sorted(unique_idx)]\n",
    "    ivs = ivs[sorted(unique_idx)]\n",
    "\n",
    "    if len(days) < 2:\n",
    "        warnings.warn(f\"Not enough unique days to interpolate for ticker {ticker}.\")\n",
    "        return\n",
    "\n",
    "    spline = interp1d(days, ivs, kind=\"linear\", fill_value=\"extrapolate\")\n",
    "\n",
    "    def term_spline(dte):\n",
    "        if dte < days[0]:\n",
    "            return ivs[0]\n",
    "        elif dte > days[-1]:\n",
    "            return ivs[-1]\n",
    "        else:\n",
    "            return float(spline(dte))\n",
    "\n",
    "    return term_spline\n",
    "\n",
    "\n",
    "def get_current_price(df_price_history_3mo):\n",
    "    return df_price_history_3mo[\"Close\"].iloc[-1]\n",
    "\n",
    "\n",
    "def calc_kelly_bet(p_win: float = 0.66, odds_decimal: float = 1.66, current_bankroll: float = 10000,\n",
    "                   pct_kelly=0.10) -> float:\n",
    "    \"\"\"\n",
    "    Calculates the Kelly Criterion optimal bet amount.\n",
    "\n",
    "    The Kelly Criterion is a formula used to determine the optimal size of a series\n",
    "    of bets to maximize the long-term growth rate of a bankroll.\n",
    "\n",
    "    Args:\n",
    "        p_win: The estimated probability of winning the bet (p),\n",
    "                                a float between 0 and 1.\n",
    "        odds_decimal: The decimal odds (b), where a successful $1 bet returns $b.\n",
    "                      For example, if odds are 2:1, odds_decimal is 3.0.\n",
    "                      If odds are 1:1, odds_decimal is 2.0.\n",
    "                      This is (payout / stake) + 1.\n",
    "        current_bankroll: The total amount of money available to bet (B).\n",
    "\n",
    "    Returns:\n",
    "        The calculated optimal bet amount. Returns 0 if the bet is not favorable\n",
    "        (i.e., the calculated fraction is negative or zero), or if inputs are invalid.\n",
    "    \"\"\"\n",
    "    if not (0 <= p_win <= 1):\n",
    "        raise ValueError(\"Probability of winning must be between 0 and 1.\")\n",
    "    if odds_decimal <= 1.0:  # Odds must be greater than 1.0 (e.g., 1.01 for a tiny profit)\n",
    "        raise ValueError(\"Decimal odds must be greater than 1.0 (e.g., 1.01 for a winning bet).\")\n",
    "    if current_bankroll <= 0:\n",
    "        raise ValueError(\"Current bankroll must be a positive number.\")\n",
    "\n",
    "    b_kelly = odds_decimal - 1.0\n",
    "\n",
    "    if b_kelly <= 0:  # Should be caught by odds_decimal check, but as a safeguard\n",
    "        return 0.0\n",
    "\n",
    "    kelly_fraction = p_win - ((1 - p_win) / b_kelly)\n",
    "\n",
    "    if kelly_fraction <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    bet_amount = kelly_fraction * current_bankroll\n",
    "    bet_amount = bet_amount * pct_kelly\n",
    "    return round(bet_amount, 2)\n",
    "\n",
    "\n",
    "def get_all_usa_tickers(use_yf_db=True, earnings_date=datetime.today().strftime(\"%Y-%m-%d\")):\n",
    "    ### FMP ###\n",
    "\n",
    "    try:\n",
    "        fmp_apikey = os.getenv(\"FMP_API_KEY\")\n",
    "        fmp_url = (\n",
    "            f\"https://financialmodelingprep.com/api/v3/earning_calendar?from={earnings_date}&to={earnings_date}&apikey={fmp_apikey}\"\n",
    "        )\n",
    "        fmp_response = requests.get(fmp_url)\n",
    "        df_fmp = pd.DataFrame(fmp_response.json())\n",
    "        df_fmp_usa = df_fmp[df_fmp[\"symbol\"].str.fullmatch(r\"[A-Z]{1,4}\") & ~df_fmp[\"symbol\"].str.contains(r\"[.-]\")]\n",
    "\n",
    "        fmp_usa_symbols = sorted(df_fmp_usa[\"symbol\"].unique().tolist())\n",
    "    except Exception:\n",
    "        print(\"No FMP API Key found. Only using NASDAQ\")\n",
    "        fmp_usa_symbols = []\n",
    "\n",
    "    ### NASDAQ ###\n",
    "\n",
    "    nasdaq_url = f\"https://api.nasdaq.com/api/calendar/earnings?date={earnings_date}\"\n",
    "    nasdaq_headers = {\"User-Agent\": \"Mozilla/5.0\", \"Accept\": \"application/json\"}\n",
    "    nasdaq_response = requests.get(nasdaq_url, headers=nasdaq_headers)\n",
    "    nasdaq_calendar = nasdaq_response.json().get(\"data\").get(\"rows\")\n",
    "    df_nasdaq = pd.DataFrame(nasdaq_calendar)\n",
    "    df_nasdaq = df_nasdaq[df_nasdaq[\"symbol\"].str.fullmatch(r\"[A-Z]{1,4}\") & ~df_nasdaq[\"symbol\"].str.contains(r\"[.-]\")]\n",
    "\n",
    "    nasdaq_tickers = sorted(df_nasdaq[\"symbol\"].unique().tolist())\n",
    "\n",
    "    all_usa_earnings_tickers_today = sorted(list(set(fmp_usa_symbols + nasdaq_tickers)))\n",
    "\n",
    "    return all_usa_earnings_tickers_today\n",
    "\n",
    "\n",
    "def calc_prev_earnings_stats(df_history, ticker_obj, plot_loc=PLOT_LOC):\n",
    "    df_history = df_history.copy()\n",
    "    if \"Date\" not in df_history.columns and df_history.index.name == \"Date\":\n",
    "        df_history = df_history.reset_index()\n",
    "    df_history[\"Date\"] = df_history[\"Date\"].dt.date\n",
    "    df_history = df_history.sort_values(\"Date\")\n",
    "\n",
    "    n_tries = 3\n",
    "    i = 0\n",
    "    while i < n_tries:\n",
    "        df_earnings_dates = ticker_obj.earnings_dates\n",
    "        if df_earnings_dates is not None and not df_earnings_dates.empty:\n",
    "            break\n",
    "        i += 1\n",
    "\n",
    "    if df_earnings_dates is None:\n",
    "        return 0, 0, 0, 0, None\n",
    "\n",
    "    df_earnings_dates = df_earnings_dates.reset_index()\n",
    "    df_earnings_dates = df_earnings_dates[df_earnings_dates[\"Event Type\"] == \"Earnings\"].copy()\n",
    "    df_earnings_dates[\"Date\"] = df_earnings_dates[\"Earnings Date\"].dt.date\n",
    "\n",
    "    def classify_release(dt):\n",
    "        hour = dt.hour\n",
    "        if hour < 9:\n",
    "            return \"pre-market\"\n",
    "        elif hour >= 9:\n",
    "            return \"post-market\"\n",
    "\n",
    "    df_earnings_dates[\"release_timing\"] = df_earnings_dates[\"Earnings Date\"].apply(classify_release)\n",
    "    df_earnings = df_earnings_dates.merge(df_history, on=\"Date\", how=\"left\", suffixes=('', '_earnings'))\n",
    "    df_earnings[\"next_date\"] = df_earnings[\"Date\"] + pd.Timedelta(days=1)\n",
    "    df_next = df_history.rename(columns=lambda c: f\"{c}_next\" if c != \"Date\" else \"next_date\")\n",
    "    df_flat = df_earnings.merge(df_next, on=\"next_date\", how=\"left\")\n",
    "    df_flat[\"prev_close\"] = df_flat[\"Close\"].shift(1)\n",
    "    df_flat[\"pre_market_move\"] = (df_flat[\"Open\"] - df_flat[\"prev_close\"]) / df_flat[\"prev_close\"]\n",
    "    df_flat[\"post_market_move\"] = (df_flat[\"Open_next\"] - df_flat[\"Close\"]) / df_flat[\"Close\"]\n",
    "\n",
    "    df_flat[\"earnings_move\"] = df_flat.apply(\n",
    "        lambda row: row[\"pre_market_move\"] if row[\"release_timing\"] == \"pre-market\"\n",
    "        else row[\"post_market_move\"] if row[\"release_timing\"] == \"post-market\"\n",
    "        else None,\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    if plot_loc and df_flat.shape[0]:\n",
    "        df_flat[\"text\"] = (df_flat[\"earnings_move\"] * 100).round(2).astype(str) + \"%\"\n",
    "        p = px.bar(\n",
    "            x=df_flat[\"Date\"],\n",
    "            y=df_flat[\"earnings_move\"].round(3),\n",
    "            color=df_flat.index.astype(str),\n",
    "            text=df_flat[\"text\"],\n",
    "            title=\"Earnings % Move\",\n",
    "        )\n",
    "        p.update_traces(textangle=0)\n",
    "        # p.show()\n",
    "\n",
    "        full_path = os.path.join(plot_loc, f\"{ticker}_{df_flat[\"Date\"].iloc[0].strftime(\"%Y-%m-%d\")}.html\")\n",
    "        os.makedirs(plot_loc, exist_ok=True)\n",
    "        p.write_html(full_path)\n",
    "        print(f\"Saved plot for ticker {ticker} here: {full_path}\")\n",
    "\n",
    "    avg_abs_pct_move = round(abs(df_flat[\"earnings_move\"]).mean(), 3)\n",
    "    prev_earnings_std = round(abs(df_flat[\"earnings_move\"]).std(ddof=1), 3)\n",
    "    median_abs_pct_move = round(abs(df_flat[\"earnings_move\"]).median(), 3)\n",
    "    min_abs_pct_move = round(abs(df_flat[\"earnings_move\"]).min(), 3)\n",
    "    max_abs_pct_move = round(abs(df_flat[\"earnings_move\"]).max(), 3)\n",
    "    earnings_release_timing_mode = df_flat[\"release_timing\"].mode()\n",
    "    release_time = earnings_release_timing_mode.iloc[0] if not earnings_release_timing_mode.empty else \"unknown\"\n",
    "    prev_earnings_values = df_flat[\"earnings_move\"].dropna().values\n",
    "\n",
    "    if prev_earnings_std < 0.001:\n",
    "        prev_earnings_std = 0.001  # avoid division by 0 or overly tight thresholds\n",
    "\n",
    "    return avg_abs_pct_move, median_abs_pct_move, min_abs_pct_move, max_abs_pct_move, prev_earnings_std, release_time, prev_earnings_values\n",
    "\n",
    "\n",
    "def compute_recommendation(\n",
    "        ticker,\n",
    "        min_avg_30d_dollar_volume=MIN_AVG_30D_DOLLAR_VOLUME,\n",
    "        min_avg_30d_share_volume=MIN_AVG_30D_SHARE_VOLUME,\n",
    "        min_iv30_rv30=MIN_IV30_RV30,\n",
    "        max_ts_slope_0_45=MAX_TS_SLOPE_0_45,\n",
    "        plot_loc=PLOT_LOC,\n",
    "):\n",
    "    ticker = ticker.strip().upper()\n",
    "    if not ticker:\n",
    "        return \"No stock symbol provided.\"\n",
    "\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        n_tries = 3\n",
    "        i = 0\n",
    "        while i < n_tries:\n",
    "            exp_dates = list(stock.options)\n",
    "            if exp_dates:\n",
    "                break\n",
    "            i += 1\n",
    "        if len(exp_dates) == 0:\n",
    "            raise KeyError(f\"No options data found for ticker {ticker}\")\n",
    "    except KeyError:\n",
    "        return f\"Error: No options found for stock symbol '{ticker}'.\"\n",
    "\n",
    "    try:\n",
    "        exp_dates = filter_dates(exp_dates)\n",
    "    except Exception:\n",
    "        return \"Error: Not enough option data.\"\n",
    "\n",
    "    options_chains = {}\n",
    "    for exp_date in exp_dates:\n",
    "        n_tries = 3\n",
    "        i = 0\n",
    "        while i < n_tries:\n",
    "            chain = stock.option_chain(exp_date)\n",
    "            options_chains[exp_date] = chain\n",
    "            if chain is not None and len(chain):\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "    n_tries = 3\n",
    "    i = 0\n",
    "    while i < n_tries:\n",
    "        df_history = stock.history(\n",
    "            start=(datetime.today() - timedelta(days=EARNINGS_LOOKBACK_DAYS_FOR_AGG)).strftime(\"%Y-%m-%d\"))\n",
    "        if df_history is not None and not df_history.empty:\n",
    "            break\n",
    "        i += 1\n",
    "\n",
    "    # df_price_history_3mo = stock.history(period=\"3mo\")\n",
    "\n",
    "    df_price_history_3mo = df_history[\n",
    "        df_history.index >= (pd.Timestamp.now(df_history.index.tz) - relativedelta(months=3))]\n",
    "    # df_price_history_3mo = df_history[df_history.index >= (datetime.now(pytz.timezone(\"America/New_York\")) - relativedelta(months=3))]\n",
    "    df_price_history_3mo = df_price_history_3mo.sort_index()\n",
    "    df_price_history_3mo[\"dollar_volume\"] = df_price_history_3mo[\"Volume\"] * df_price_history_3mo[\"Close\"]\n",
    "\n",
    "    try:\n",
    "        underlying_price = get_current_price(df_price_history_3mo)\n",
    "        if underlying_price is None:\n",
    "            raise ValueError(\"No market price found.\")\n",
    "    except Exception:\n",
    "        return \"Error: Unable to retrieve underlying stock price.\"\n",
    "\n",
    "    atm_iv = {}\n",
    "    straddle = None\n",
    "    i = 0\n",
    "    for exp_date, chain in options_chains.items():\n",
    "        calls = chain.calls\n",
    "        puts = chain.puts\n",
    "\n",
    "        if calls is None or puts is None or calls.empty or puts.empty:\n",
    "            continue\n",
    "\n",
    "        call_diffs = (calls[\"strike\"] - underlying_price).abs()\n",
    "        call_idx = call_diffs.idxmin()\n",
    "        call_iv = calls.loc[call_idx, \"impliedVolatility\"]\n",
    "\n",
    "        put_diffs = (puts[\"strike\"] - underlying_price).abs()\n",
    "        put_idx = put_diffs.idxmin()\n",
    "        put_iv = puts.loc[put_idx, \"impliedVolatility\"]\n",
    "\n",
    "        atm_iv_value = (call_iv + put_iv) / 2.0\n",
    "        atm_iv[exp_date] = atm_iv_value\n",
    "\n",
    "        if i == 0:\n",
    "            call_bid = calls.loc[call_idx, \"bid\"]\n",
    "            call_ask = calls.loc[call_idx, \"ask\"]\n",
    "            put_bid = puts.loc[put_idx, \"bid\"]\n",
    "            put_ask = puts.loc[put_idx, \"ask\"]\n",
    "\n",
    "            if call_bid is not None and call_ask is not None:\n",
    "                call_mid = (call_bid + call_ask) / 2.0\n",
    "            else:\n",
    "                call_mid = None\n",
    "\n",
    "            if put_bid is not None and put_ask is not None:\n",
    "                put_mid = (put_bid + put_ask) / 2.0\n",
    "            else:\n",
    "                put_mid = None\n",
    "\n",
    "            if call_mid is not None and put_mid is not None and call_mid != 0 and put_mid != 0:\n",
    "                straddle = call_mid + put_mid\n",
    "            else:\n",
    "                try:\n",
    "                    if call_idx + 1 < len(calls) and put_idx + 1 < len(puts):\n",
    "                        warnings.warn(f\"For ticker {ticker} straddle is either 0 or None from available bid/ask spread... using nearest term strikes.\")\n",
    "                        straddle = calls.iloc[call_idx + 1][\"lastPrice\"] + puts.iloc[put_idx + 1][\"lastPrice\"]\n",
    "                    if not straddle:\n",
    "                        warnings.warn(f\"For ticker {ticker} straddle is either 0 or None from available bid/ask spread... using lastPrice.\")\n",
    "                        straddle = calls.iloc[call_idx][\"lastPrice\"] + puts.iloc[call_idx][\"lastPrice\"]\n",
    "                except IndexError:\n",
    "                    warnings.warn(f\"For ticker {ticker}, call_idx {call_idx} is out of bounds in calls/puts.\")\n",
    "                    return None\n",
    "        i += 1\n",
    "\n",
    "    if not atm_iv:\n",
    "        return \"Error: Could not determine ATM IV for any expiration dates.\"\n",
    "\n",
    "    today = datetime.today().date()\n",
    "    dtes = []\n",
    "    ivs = []\n",
    "    for exp_date, iv in atm_iv.items():\n",
    "        exp_date_obj = datetime.strptime(exp_date, \"%Y-%m-%d\").date()\n",
    "        days_to_expiry = (exp_date_obj - today).days\n",
    "        dtes.append(days_to_expiry)\n",
    "        ivs.append(iv)\n",
    "\n",
    "    term_spline = build_term_structure(dtes, ivs)\n",
    "    if not term_spline:\n",
    "        return\n",
    "\n",
    "    ts_slope_0_45 = (term_spline(45) - term_spline(dtes[0])) / (45 - dtes[0])\n",
    "\n",
    "    iv30_rv30 = term_spline(30) / yang_zhang(df_price_history_3mo)\n",
    "\n",
    "    rolling_share_volume = df_price_history_3mo[\"Volume\"].rolling(30).mean().dropna()\n",
    "    rolling_dollar_volume = df_price_history_3mo[\"dollar_volume\"].rolling(30).mean().dropna()\n",
    "\n",
    "    if rolling_share_volume.empty:\n",
    "        avg_share_volume = 0\n",
    "    else:\n",
    "        avg_share_volume = rolling_share_volume.iloc[-1]\n",
    "\n",
    "    if rolling_dollar_volume.empty:\n",
    "        avg_dollar_volume = 0\n",
    "    else:\n",
    "        avg_dollar_volume = rolling_dollar_volume.iloc[-1]\n",
    "\n",
    "    expected_move_straddle = (straddle / underlying_price).round(3) if straddle else None\n",
    "\n",
    "    (\n",
    "        prev_earnings_avg_abs_pct_move, prev_earnings_median_abs_pct_move, prev_earnings_min_abs_pct_move,\n",
    "        prev_earnings_max_abs_pct_move, prev_earnings_std, earnings_release_time, prev_earnings_values\n",
    "     ) = calc_prev_earnings_stats(df_history.reset_index(), stock, plot_loc=plot_loc)\n",
    "\n",
    "    result_summary = {\n",
    "        \"avg_30d_dollar_volume\": round(avg_dollar_volume, 3),\n",
    "        \"avg_30d_dollar_volume_pass\": avg_dollar_volume >= min_avg_30d_dollar_volume,\n",
    "        \"avg_30d_share_volume\": round(avg_share_volume, 3),\n",
    "        \"avg_30d_share_volume_pass\": avg_share_volume >= min_avg_30d_share_volume,\n",
    "        \"iv30_rv30\": round(iv30_rv30, 3),\n",
    "        \"iv30_rv30_pass\": iv30_rv30 >= min_iv30_rv30,\n",
    "        \"ts_slope_0_45\": ts_slope_0_45,\n",
    "        \"ts_slope_0_45_pass\": ts_slope_0_45 <= max_ts_slope_0_45,\n",
    "        \"underlying_price\": underlying_price,\n",
    "        \"call_spread\": (call_bid, call_ask),\n",
    "        \"put_spread\": (put_bid, put_ask),\n",
    "        \"expected_move_straddle\": (expected_move_straddle * 100).round(3).astype(str) + \"%\",\n",
    "        \"straddle_pct_move_ge_hist_pct_move_pass\": expected_move_straddle >= prev_earnings_avg_abs_pct_move,\n",
    "        \"prev_earnings_avg_abs_pct_move\": str(round(prev_earnings_avg_abs_pct_move * 100, 3)) + \"%\",\n",
    "        \"prev_earnings_median_abs_pct_move\": str(round(prev_earnings_median_abs_pct_move * 100, 3)) + \"%\",\n",
    "        \"prev_earnings_min_abs_pct_move\": str(round(prev_earnings_min_abs_pct_move * 100, 3)) + \"%\",\n",
    "        \"prev_earnings_max_abs_pct_move\": str(round(prev_earnings_max_abs_pct_move * 100, 3)) + \"%\",\n",
    "        \"prev_earnings_values\": [str(round(v * 100, 3)) + \"%\" for v in prev_earnings_values],\n",
    "        \"earnings_release_time\": earnings_release_time\n",
    "    }\n",
    "\n",
    "    if (\n",
    "            result_summary[\"avg_30d_dollar_volume_pass\"]\n",
    "            and result_summary[\"iv30_rv30_pass\"]\n",
    "            and result_summary[\"ts_slope_0_45_pass\"]\n",
    "            and result_summary[\"avg_30d_share_volume_pass\"]\n",
    "    ):\n",
    "        original_suggestion = \"Recommended\"\n",
    "    elif result_summary[\"ts_slope_0_45_pass\"] and (\n",
    "            (result_summary[\"avg_30d_dollar_volume_pass\"] and not result_summary[\"iv30_rv30_pass\"])\n",
    "            or (result_summary[\"iv30_rv30_pass\"] and not result_summary[\"avg_30d_dollar_volume_pass\"])\n",
    "    ):\n",
    "        original_suggestion = \"Consider\"\n",
    "    else:\n",
    "        original_suggestion = \"Avoid\"\n",
    "\n",
    "    if (\n",
    "            result_summary[\"avg_30d_dollar_volume_pass\"]\n",
    "            and result_summary[\"iv30_rv30_pass\"]\n",
    "            and result_summary[\"ts_slope_0_45_pass\"]\n",
    "            and result_summary[\"avg_30d_share_volume_pass\"]\n",
    "            and result_summary[\"underlying_price\"] >= MIN_SHARE_PRICE\n",
    "            and result_summary[\"straddle_pct_move_ge_hist_pct_move_pass\"]\n",
    "            and expected_move_straddle > prev_earnings_min_abs_pct_move  # safety filter - data quality check\n",
    "    ):\n",
    "        improved_suggestion = \"Highly Recommended\"\n",
    "    elif (\n",
    "            result_summary[\"avg_30d_dollar_volume_pass\"]\n",
    "            and result_summary[\"iv30_rv30_pass\"]\n",
    "            and result_summary[\"ts_slope_0_45_pass\"]\n",
    "            and result_summary[\"avg_30d_share_volume_pass\"]\n",
    "            and result_summary[\"underlying_price\"] >= MIN_SHARE_PRICE\n",
    "            and prev_earnings_avg_abs_pct_move - expected_move_straddle <= 0.75 * prev_earnings_std  # Avg move - Straddle is within 0.75 std deviations\n",
    "            and expected_move_straddle > prev_earnings_min_abs_pct_move  # Safety filter - data quality check\n",
    "    ):\n",
    "        improved_suggestion = \"Slightly Recommended\"\n",
    "    elif (\n",
    "            result_summary[\"avg_30d_dollar_volume_pass\"]\n",
    "            and result_summary[\"iv30_rv30_pass\"]\n",
    "            and result_summary[\"ts_slope_0_45_pass\"]\n",
    "            and result_summary[\"avg_30d_share_volume_pass\"]\n",
    "            and result_summary[\"underlying_price\"] >= MIN_SHARE_PRICE\n",
    "            and prev_earnings_avg_abs_pct_move - expected_move_straddle <= 0.50 * prev_earnings_std  # Avg move - Straddle is within 0.50 std deviations\n",
    "            and expected_move_straddle > prev_earnings_min_abs_pct_move  # Safety filter - data quality check\n",
    "    ):\n",
    "        improved_suggestion = \"Recommended\"\n",
    "    elif result_summary[\"ts_slope_0_45_pass\"] and result_summary[\"avg_30d_dollar_volume_pass\"] and result_summary[\n",
    "        \"iv30_rv30_pass\"] and expected_move_straddle * 1.5 < prev_earnings_min_abs_pct_move:\n",
    "        improved_suggestion = \"Consider...\"\n",
    "    elif result_summary[\"ts_slope_0_45_pass\"] and result_summary[\"avg_30d_dollar_volume_pass\"] and result_summary[\n",
    "        \"iv30_rv30_pass\"]:\n",
    "        improved_suggestion = \"Original Consider...\"\n",
    "    elif result_summary[\"ts_slope_0_45_pass\"] and (\n",
    "            (result_summary[\"avg_30d_dollar_volume_pass\"] and not result_summary[\"iv30_rv30_pass\"])\n",
    "            or (result_summary[\"iv30_rv30_pass\"] and not result_summary[\"avg_30d_dollar_volume_pass\"])\n",
    "    ):\n",
    "        improved_suggestion = \"Eh... Consider, but it's risky!\"\n",
    "    else:\n",
    "        improved_suggestion = \"Avoid\"\n",
    "\n",
    "    edge_score = 0\n",
    "\n",
    "    # IV to RV ratio\n",
    "    if iv30_rv30 > 2.0:\n",
    "        edge_score += 1.0\n",
    "    elif iv30_rv30 > 1.5:\n",
    "        edge_score += 0.5\n",
    "\n",
    "    # Term structure slope\n",
    "    if ts_slope_0_45 < -0.01:\n",
    "        edge_score += 0.5\n",
    "\n",
    "    # Liquidity\n",
    "    if avg_dollar_volume > 50_000_000:\n",
    "        edge_score += 0.5\n",
    "\n",
    "    # Straddle expected pct change >= avg earnings pct change\n",
    "    if expected_move_straddle >= prev_earnings_avg_abs_pct_move:\n",
    "        edge_score += 1.0\n",
    "\n",
    "    if \"Recommended\" in improved_suggestion:\n",
    "        if edge_score >= 3.0:\n",
    "            kelly_multiplier_from_base = 2.0\n",
    "        elif edge_score >= 2.5:\n",
    "            kelly_multiplier_from_base = 1.75\n",
    "        elif edge_score >= 2.0:\n",
    "            kelly_multiplier_from_base = 1.5\n",
    "        elif edge_score >= 1.5:\n",
    "            kelly_multiplier_from_base = 1.25\n",
    "        elif edge_score >= 1:\n",
    "            kelly_multiplier_from_base = 1.125\n",
    "        elif edge_score >= 0.5:\n",
    "            kelly_multiplier_from_base = 1.0\n",
    "        elif edge_score == 0:\n",
    "            kelly_multiplier_from_base = 0.80\n",
    "    elif \"Consider\" in improved_suggestion:\n",
    "        kelly_multiplier_from_base = 0.5\n",
    "    elif original_suggestion == \"Consider\":\n",
    "        kelly_multiplier_from_base = 0.2\n",
    "    else:\n",
    "        kelly_multiplier_from_base = 0\n",
    "\n",
    "    result_summary[\"improved_suggestion\"] = improved_suggestion\n",
    "    result_summary[\"original_suggestion\"] = original_suggestion\n",
    "    kelly_bet = calc_kelly_bet()\n",
    "\n",
    "    kelly_bet = round(kelly_bet * kelly_multiplier_from_base, 2)\n",
    "    result_summary[\"kelly_multiplier_from_base\"] = kelly_multiplier_from_base\n",
    "    result_summary[\"kelly_bet\"] = kelly_bet\n",
    "    return result_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b1539da-dbb4-4d7a-805a-1cc600bc64e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning 1 tickers: \n",
      "['AAPL']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "earnings_date = None  # args.earnings_date\n",
    "tickers = [\"AAPL\"]  # tickers = args.tickers\n",
    "verbose = True  # args.verbose\n",
    "\n",
    "if tickers == [\"_all\"]:\n",
    "    tickers = get_all_usa_tickers(earnings_date=earnings_date)\n",
    "\n",
    "print(f\"Scanning {len(tickers)} tickers: \\n{tickers}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fe40268-6f39-4544-8c46-249b65ee0beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot for ticker AAPL here: /Users/melgazar9/tmp_plots/AAPL_2025-05-01.html\n",
      " *** EDGE FOUND ***\n",
      "\n",
      "ticker: AAPL\n",
      "  avg_30d_dollar_volume: 10687500246.769\n",
      "  avg_30d_dollar_volume_pass: True\n",
      "  avg_30d_share_volume: 51463026.667\n",
      "  avg_30d_share_volume_pass: True\n",
      "  iv30_rv30: 1.479\n",
      "  iv30_rv30_pass: True\n",
      "  ts_slope_0_45: -0.00933001217086594\n",
      "  ts_slope_0_45_pass: True\n",
      "  underlying_price: 209.0500030517578\n",
      "  call_spread: (np.float64(3.7), np.float64(3.75))\n",
      "  put_spread: (np.float64(4.85), np.float64(5.0))\n",
      "  expected_move_straddle: 4.1%\n",
      "  straddle_pct_move_ge_hist_pct_move_pass: True\n",
      "  prev_earnings_avg_abs_pct_move: 3.1%\n",
      "  prev_earnings_median_abs_pct_move: 3.0%\n",
      "  prev_earnings_min_abs_pct_move: 0.4%\n",
      "  prev_earnings_max_abs_pct_move: 7.9%\n",
      "  prev_earnings_values: ['-3.389%', '4.041%', '-2.187%', '0.362%', '7.871%', '-3.746%', '-1.875%', '-2.955%', '3.13%', '-1.85%', '2.348%']\n",
      "  earnings_release_time: post-market\n",
      "  improved_suggestion: Highly Recommended\n",
      "  original_suggestion: Recommended\n",
      "  kelly_multiplier_from_base: 1.25\n",
      "  kelly_bet: 181.06\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "for ticker in tickers:\n",
    "    result = compute_recommendation(ticker)\n",
    "    is_edge = isinstance(result, dict) and \"Recommended\" in result.get(\"improved_suggestion\")\n",
    "    if is_edge:\n",
    "        print(\" *** EDGE FOUND ***\\n\")\n",
    "\n",
    "    if verbose or is_edge:\n",
    "        print(f\"ticker: {ticker}\")\n",
    "        if isinstance(result, dict):\n",
    "            for k, v in result.items():\n",
    "                print(f\"  {k}: {v}\")\n",
    "        else:\n",
    "            print(f\"  {result}\")\n",
    "        print(\"---------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080d3228-930f-439e-8473-01b1a13a4dde",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f766124c-766d-4629-932f-36469a8af6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4409acf3-9cb6-408e-af37-b23c510d7420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a31e701-ecfc-4cb2-8899-e25c429ad1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "df_flat[\"text\"] = (df_flat[\"open_pct_change\"] * 100).round(3).astype(str) + \"%\"\n",
    "\n",
    "p = px.bar(\n",
    "    x=df_flat[\"Date\"],\n",
    "    y=df_flat[\"open_pct_change\"].round(3),\n",
    "    color=df_flat.index.astype(str),\n",
    "    title=\"Open % Change\",\n",
    "    text=df_flat[\"text\"]\n",
    ")\n",
    "\n",
    "p.update_traces(textangle=0)\n",
    "\n",
    "p.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
